### http 的 1.0 1.1 2.0 的区别和改进

参考链接：https://blog.fundebug.com/2019/03/07/understand-http2-and-http3/

**Http1.0**

-   链接无法复用 传输数据每次都需要重新建立连接
-   头部阻塞 ，如果一个包阻塞，后续的资源需要等待当前请求完成以后才能发起请求

**http1.1**

-   缓存处理 加入了很多缓存头来控制缓存策略
-   长连接 一定程度上 减少了 http1.0 每次请求都要创建链接的缺点

-   -   tcp 链接默认不关闭 可以被多个请求复用 （大多数浏览器允许同时建立 6 个持久链接）
-   -   但是同一个 tcp 链接中 数据通信是按照次序进行的
-   管道机制： 同一个 tcp 中 客户端可以发送多个请求，但是返回是有序的，仍然需要处理
-   长连接的弊端：
    一般的 http 请求都有需要遵守 请求-响应 的过程；就是客户端发送一个请求等待服务端返回数据才能进行下一次请求发送；（可以理解为多个请求是串行发送的），这时如果页面中存在多个请求；每个请求必须等到前一个请求响应完毕之后才能发送；这时候如果某一个请求发生了延时，导致后边的也发送不了，这时就造成了队头阻塞；

    串行的效率是比较低的；为了提高效率和速度，长连接还可以开启管道模式；可以将请求的发送改成并行的；管道化允许客户端在已发送的请求收到服务端的响应之前发送下一个请求；
    client 并行发起多个请求，服务端收到请求就响应哪一个请求；客户端请求响应是按照接收到请求的顺序来的，先接收的先响应，后接收的后响应；这时候如果其中某一个响应出现了问题被阻塞了，后边接收到的响应必须等待，这时候也出现了队头阻塞

**http2.0**

1. 采用二进制格式 而非文本格式 ，二进制分帧可以乱序发送，通过帧的首部流标识进行排序
2. 采用多路复用 真正的实现并行 支持请求优先级
    - 同域名下所有通信都在单个链接上完成
    - 单个链接可以承载任意数量的双向数据流
    - 数据流由消息发送 消息由帧组成，多个帧之间可以乱序发送
3. 使用头部压缩 降低开销
4. 支持服务端推送

**http3.0**

> 背景: http2.x 中的 tcp 协议 如果出现了丢包的情况，整个 tcp 都要等待重传，导致后面的数据被阻塞。于是 http3 新增一个 quic 的协议，

1. 实现数据传输步骤更加简单，速度更快
2. 多路复用 一个连接上的多个 stream 之间没有依赖，丢包之后不影响其他请求，也就不存在 TCP 队头阻塞。
3. tcp 基于 ip 和端口，而 quic 通过 id 的方式去识别连接，在移动端的表现比 tcp 好。
